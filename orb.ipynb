{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Muttabi Hudaya\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\Lib\\\\site-packages\\\\cv2\\\\python-3.8\\\\cv2.cp38-win_amd64.pyd'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os.path import realpath, normpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.cuda.getCudaEnabledDeviceCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_ORB_TEST_IMG = 'results/cropped/e-ktp/'\n",
    "img_ = PATH_TO_ORB_TEST_IMG + '10_card_crop_0.jpg'\n",
    "img2 = PATH_TO_ORB_TEST_IMG + '7_card_crop_0.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check smaller width dimension of 2 images\n",
    "# Smaller images: check width x dimension and choose the smaller\n",
    "# Resize higher image resolution with the smaller dimension (width / height)\n",
    "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is Noner\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "\n",
    "    # return the resized image\n",
    "    return resized\n",
    "\n",
    "def get_downscaled_images(img1, img2):\n",
    "    img1_h, img1_w, = img1.shape\n",
    "    img2_h, img2_w, = img2.shape\n",
    "    \n",
    "    if img1_h > img2_h:\n",
    "        scaled_img1 = image_resize(img1, width=img2_w)\n",
    "        scaled_img2 = img2\n",
    "    else:\n",
    "        scaled_img2 = image_resize(img2, width=img1_w)\n",
    "        scaled_img1 = img1\n",
    "        \n",
    "    \n",
    "    return scaled_img1, scaled_img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original Dimensions : ',img.shape)\n",
    " \n",
    "width = 350\n",
    "height = 450\n",
    "dim = (width, height)\n",
    " \n",
    "# resize image\n",
    "resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1,2)\n",
    "\n",
    "img_show1 = cv2.imread(img_)\n",
    "img_show1 = cv2.cvtColor(img_show1, cv2.COLOR_BGR2RGB)\n",
    "img_show2 = cv2.imread(img2)\n",
    "img_show2 = cv2.cvtColor(img_show2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20,10]\n",
    "ax1.set_title('Image 1')\n",
    "ax1.imshow(img_show1)\n",
    "ax2.set_title('Image 2')\n",
    "ax2.imshow(img_show2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(471, 690, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_show1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(342, 550, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_show2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_img1, rescaled_img2 = get_downscaled_images(img_show1, img_show2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 550, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaled_img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(342, 550, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaled_img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1,2)\n",
    "plt.rcParams['figure.figsize'] = [20,10]\n",
    "ax1.set_title('Colored image')\n",
    "ax1.imshow(rescaled_img1)\n",
    "ax2.set_title('Grayed image')\n",
    "ax2.imshow(rescaled_img2, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "img1 = cv2.imread(img_)\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img1_gray = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1,2)\n",
    "plt.rcParams['figure.figsize'] = [20,10]\n",
    "ax1.set_title('Colored image')\n",
    "ax1.imshow(img1)\n",
    "ax2.set_title('Grayed image')\n",
    "ax2.imshow(img1_gray, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1=rescaled_img1\n",
    "img1_gray=cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
    "img2=rescaled_img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ORB Keypoints and Descriptor\n",
    "n_features = 3000\n",
    "factor = 2.0\n",
    "orb = cv2.ORB_create(n_features)\n",
    "corb = cv2.cuda_ORB.create(n_features)\n",
    "\n",
    "def get_orb_kp_and_des(img_path, with_cuda=False):\n",
    "    img1 = cv2.imread(img_path)\n",
    "    if with_cuda:\n",
    "        cuMat1 = cv2.cuda_GpuMat()\n",
    "        cuMat1.upload(img1)\n",
    "        cuMat1_gray = cv2.cuda.cvtColor(cuMat1, cv2.COLOR_BGR2GRAY)\n",
    "        print(\"here\")\n",
    "        _kps1, _descs1 = corb.detectAndComputeAsync(cuMat1_gray, None)\n",
    "        keypoints_img = corb.convert(_kps1)\n",
    "        descriptor_img = _descs1\n",
    "    else:\n",
    "        img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "        keypoints_img, descriptor_img =  orb.detectAndCompute(img1_gray, None)\n",
    "    return keypoints_img, descriptor_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts key points\n",
    "n_features = 3000\n",
    "factor = 2.0\n",
    "orb = cv2.ORB_create(n_features, factor)\n",
    "\n",
    "PATH_TO_ORB_TEST_IMG = 'results/cropped/e-ktp/'\n",
    "img_ = PATH_TO_ORB_TEST_IMG + '10_card_crop_0.jpg'\n",
    "img2 = PATH_TO_ORB_TEST_IMG + '7_card_crop_0.jpg'\n",
    "npMat1 = cv2.imread(img_)\n",
    "npMat2 = cv2.imread(img2)\n",
    "# upload into Cuda\n",
    "cuMat1 = cv2.cuda_GpuMat()\n",
    "cuMat2 = cv2.cuda_GpuMat()\n",
    "cuMat1.upload(npMat1)\n",
    "cuMat2.upload(npMat2)        \n",
    "#convert to Gray\n",
    "cuMat1g = cv2.cuda.cvtColor(cuMat1, cv2.COLOR_BGR2GRAY)\n",
    "cuMat2g = cv2.cuda.cvtColor(cuMat2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#ORB\n",
    "corb = cv2.cuda_ORB.create()\n",
    "_kps1, _descs1 = corb.detectAndComputeAsync(cuMat1g, None)\n",
    "_kps2, _descs2 = corb.detectAndComputeAsync(cuMat2g, None)\n",
    "\n",
    "#convert Keypoints to CPU\n",
    "kps1 = corb.convert(_kps1)\n",
    "kps2 = corb.convert(_kps2) \n",
    "\n",
    "#BruteForce Matching\n",
    "cbf = cv2.cuda_DescriptorMatcher.createBFMatcher(cv2.NORM_HAMMING)\n",
    "cmatches = cbf.match(_descs1, _descs2) \n",
    "# Sort matches by score\n",
    "cmatches.sort(key=lambda x: x.distance, reverse=False)\n",
    "\n",
    "print(len(cmatches))\n",
    "\n",
    "# Remove not so good matches\n",
    "# numGoodMatches = int(len(cmatches) * 0.15)\n",
    "# cmatches = cmatches[:numGoodMatches]  \n",
    "# Draw top matches\n",
    "imMatches = cv2.drawMatches(npMat1, kps1, npMat2, kps2, cmatches[:73], None)\n",
    "plt.title('Best Matching Points')\n",
    "plt.imshow(imMatches)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1,2)\n",
    "\n",
    "img_show1 = cv2.imread(img_)\n",
    "img_show1 = cv2.cvtColor(img_show1, cv2.COLOR_BGR2RGB)\n",
    "img_show2 = cv2.imread(img2)\n",
    "img_show2 = cv2.cvtColor(img_show2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20,10]\n",
    "ax1.set_title('Image 1')\n",
    "ax1.imshow(img_show1)\n",
    "ax2.set_title('Image 2')\n",
    "ax2.imshow(img_show2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Matching\n",
    "img_to_match = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "keypoints_img, descriptor_img = sift.detectAndCompute(img1_gray, None) # No Mask\n",
    "keypoints_img_to_match, descriptor_img_to_match = sift.detectAndCompute(img_to_match, None) # No Mask\n",
    "\n",
    "bf = cv2.BFMatcher()\n",
    "\n",
    "matches_keypoints_img_to_match = bf.knnMatch(descriptor_img, descriptor_img_to_match, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2917\n",
      "2917\n",
      "837\n"
     ]
    }
   ],
   "source": [
    "# Feature Matching\n",
    "PATH_TO_ORB_TEST_IMG = 'results/cropped/e-ktp/'\n",
    "img_ = PATH_TO_ORB_TEST_IMG + '10_card_crop_0.jpg'\n",
    "img2 = PATH_TO_ORB_TEST_IMG + '7_card_crop_0.jpg'\n",
    "img2 = cv2.imread(img2)\n",
    "img1_gray = cv2.cvtColor(cv2.imread(img_), cv2.COLOR_BGR2GRAY)\n",
    "img_to_match = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "img1_gray, img_to_match = get_downscaled_images(img1_gray, img_to_match)\n",
    "\n",
    "keypoints_img, descriptor_img = orb.detectAndCompute(img1_gray, None) # No Mask\n",
    "keypoints_img_to_match, descriptor_img_to_match = orb.detectAndCompute(img_to_match, None) # No Mask\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "# matches_keypoints_img_to_match = bf.knnMatch(descriptor_img, descriptor_img_to_match, k=1)\n",
    "# Match descriptors.\n",
    "matches_keypoints_img_to_match = bf.match(descriptor_img,descriptor_img_to_match)\n",
    "# Sort them in the order of their distance.\n",
    "matches_keypoints_img_to_match = sorted(matches_keypoints_img_to_match, key = lambda x:x.distance)\n",
    "\n",
    "\n",
    "numGoodMatches = int(len(matches_keypoints_img_to_match) * 0.15)\n",
    "\n",
    "print(len(keypoints_img))\n",
    "print(len(keypoints_img_to_match))\n",
    "print(len(matches_keypoints_img_to_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2917\n",
      "837\n",
      "789\n"
     ]
    }
   ],
   "source": [
    "# Apply ratio test\n",
    "good = []\n",
    "for m in matches_keypoints_img_to_match:\n",
    "    if m.distance < 64:\n",
    "        good.append(m)\n",
    "        \n",
    "print(len(keypoints_img))\n",
    "print(len(matches_keypoints_img_to_match))\n",
    "print(len(good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Draw first 10 matches.\n",
    "img3 = cv2.drawMatches(img1_gray,keypoints_img,img_to_match,keypoints_img_to_match,good,None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img3),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "971\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "# Apply ratio test\n",
    "good = []\n",
    "bad = []\n",
    "for m,n in matches_keypoints_img_to_match:\n",
    "    if m.distance < 0.75*n.distance:\n",
    "        good.append([m])\n",
    "    else:\n",
    "        bad.append([m])\n",
    "        \n",
    "print(len(matches_keypoints_img_to_match))\n",
    "print(len(good))\n",
    "\n",
    "# husen to husen : 31\n",
    "# husen to suhu (card) : 24\n",
    "# suhu to suhu (blurred): 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391\n",
      "971\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "print(len(keypoints_img_to_match))\n",
    "print(len(keypoints_img))\n",
    "print(len(good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cv2.drawMatchesKnn(img1_gray,keypoints_img, img_to_match, keypoints_img_to_match,good ,None,flags=2)\n",
    "plt.title('Best Matching Points')\n",
    "plt.imshow(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
